# ğŸ”¥ Spark ETL Project

ProfesionÃ¡lnÃ­ ETL projekt pro zpracovÃ¡nÃ­ dat pomocÃ­ Apache Spark a uloÅ¾enÃ­ do PostgreSQL databÃ¡ze.

## ğŸš€ Funkce

- âš¡ ETL proces pomocÃ­ Apache Spark
- ğŸ˜ UklÃ¡dÃ¡nÃ­ dat do PostgreSQL
- ğŸ³ KompletnÃ­ Docker prostÅ™edÃ­
- ğŸ§® Transformace CSV dat
- ğŸ“Š SprÃ¡va pomocÃ­ pgAdmin
- ğŸ”„ CI/CD pipeline s GitHub Actions
- ğŸ“… PlÃ¡novÃ¡nÃ­ Ãºloh pomocÃ­ Apache Airflow
- ğŸ“ˆ Monitoring pomocÃ­ Prometheus a Grafana
- ğŸ§© Kubernetes konfigurace pro orchestraci
- ğŸ§¹ AutomatickÃ© ÄiÅ¡tÄ›nÃ­ Docker artefaktÅ¯
- ğŸ” SprÃ¡va promÄ›nnÃ½ch prostÅ™edÃ­ a tajnÃ½ch klÃ­ÄÅ¯

## ğŸ“Š Architektura

Projekt se sklÃ¡dÃ¡ z nÄ›kolika komponent:

1. **Spark ETL Kontejner** - ZpracovÃ¡vÃ¡ a transformuje data z CSV souborÅ¯
2. **PostgreSQL DatabÃ¡ze** - UloÅ¾iÅ¡tÄ› pro transformovanÃ¡ data
3. **pgAdmin** - WebovÃ© rozhranÃ­ pro sprÃ¡vu databÃ¡ze
4. **Airflow** - Orchestrace a plÃ¡novÃ¡nÃ­ ETL procesÅ¯
5. **Prometheus/Grafana** - Monitoring a vizualizace metrik
6. **Logstash** - ZpracovÃ¡nÃ­ a analÃ½za logÅ¯

## ğŸ› ï¸ Technologie

- Apache Spark 3.5.0
- Python 3.11
- PostgreSQL
- Docker & Docker Compose
- Apache Airflow
- Prometheus & Grafana
- Kubernetes
- GitHub Actions

## âš™ï¸ Instalace a spuÅ¡tÄ›nÃ­

### PoÅ¾adavky
- Docker a Docker Compose
- Git

### RychlÃ© spuÅ¡tÄ›nÃ­

```bash
# KlonovÃ¡nÃ­ repozitÃ¡Å™e
git clone https://github.com/msm00/spark-etl-project.git
cd spark-etl-project

# SpuÅ¡tÄ›nÃ­ pomocÃ­ skriptu (vytvoÅ™Ã­ .env soubor a spustÃ­ sluÅ¾by)
bash scripts/start.sh dev
```

### ManuÃ¡lnÃ­ spuÅ¡tÄ›nÃ­

```bash
# SpuÅ¡tÄ›nÃ­ vÃ½vojovÃ©ho prostÅ™edÃ­
docker-compose up -d

# SpuÅ¡tÄ›nÃ­ produkÄnÃ­ho prostÅ™edÃ­
docker-compose -f docker-compose.prod.yml up -d

# SpuÅ¡tÄ›nÃ­ pouze ETL procesu
docker-compose up spark-etl
```

### ÄŒiÅ¡tÄ›nÃ­ Docker artefaktÅ¯

```bash
# ManuÃ¡lnÃ­ ÄiÅ¡tÄ›nÃ­
bash scripts/docker_cleanup.sh

# AutomatickÃ© ÄiÅ¡tÄ›nÃ­ (nastavenÃ­ v crontab)
# 0 1 * * 0 /path/to/docker_cleanup.sh
```

### PÅ™Ã­stup k webovÃ½m rozhranÃ­m

- **pgAdmin**: http://localhost:5050
  - Email: admin@example.com
  - Heslo: admin
- **Airflow** (pouze v produkci): http://localhost:8080
- **Prometheus** (pouze v produkci): http://localhost:9090
- **Grafana** (pouze v produkci): http://localhost:3000
  - UÅ¾ivatel: admin
  - Heslo: admin

## ğŸ§ª TestovÃ¡nÃ­

```bash
# SpuÅ¡tÄ›nÃ­ jednotkovÃ½ch testÅ¯
python -m pytest tests/

# SpuÅ¡tÄ›nÃ­ testÅ¯ s pokrytÃ­m
python -m pytest --cov=pyspark_etl_project tests/
```

## ğŸ“¦ CI/CD Pipeline

Projekt pouÅ¾Ã­vÃ¡ GitHub Actions pro automatickÃ½:
- Lint a kontrolu kÃ³du
- SpuÅ¡tÄ›nÃ­ testÅ¯
- Build a push Docker image
- ÄŒiÅ¡tÄ›nÃ­ starÃ½ch Docker images

## ğŸ”§ Kubernetes Deployment

Pro nasazenÃ­ do Kubernetes:

```bash
kubectl apply -f kubernetes/spark-etl-job.yaml
```

## ğŸ“ Struktura projektu

```
.
â”œâ”€â”€ Dockerfile                   # Definice Docker image pro Spark ETL
â”œâ”€â”€ docker-compose.yml           # Konfigurace sluÅ¾eb pro vÃ½voj
â”œâ”€â”€ docker-compose.prod.yml      # Konfigurace sluÅ¾eb pro produkci
â”œâ”€â”€ .github/workflows/           # CI/CD konfigurace
â”‚   â””â”€â”€ ci-cd.yml
â”œâ”€â”€ airflow/                     # Apache Airflow konfigurace
â”‚   â”œâ”€â”€ dags/                    # DAG definice
â”‚   â””â”€â”€ plugins/                 # Airflow pluginy
â”œâ”€â”€ kubernetes/                  # Kubernetes konfigurace
â”‚   â””â”€â”€ spark-etl-job.yaml       # Job definice
â”œâ”€â”€ monitoring/                  # Monitoring konfigurace
â”‚   â”œâ”€â”€ prometheus/              # Prometheus konfigurace
â”‚   â””â”€â”€ grafana/                 # Grafana dashboardy
â”œâ”€â”€ scripts/                     # PomocnÃ© skripty
â”‚   â”œâ”€â”€ start.sh                 # Skript pro spuÅ¡tÄ›nÃ­ prostÅ™edÃ­
â”‚   â””â”€â”€ docker_cleanup.sh        # Skript pro ÄiÅ¡tÄ›nÃ­ Docker
â”œâ”€â”€ data/                        # AdresÃ¡Å™ se zdrojovÃ½mi daty
â”‚   â””â”€â”€ users.csv                # VzorovÃ¡ data
â”œâ”€â”€ db-init/                     # SQL skripty pro inicializaci databÃ¡ze
â”‚   â””â”€â”€ 01_create_users_table.sql
â”œâ”€â”€ pgadmin/                     # Konfigurace pgAdmin
â”‚   â”œâ”€â”€ pgpassfile
â”‚   â””â”€â”€ servers.json
â”œâ”€â”€ pyspark_etl_project/         # Python kÃ³d pro ETL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ etl.py                   # HlavnÃ­ ETL skript
â””â”€â”€ tests/                       # Testy
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_etl.py              # Testy pro ETL proces
```

## ğŸ“ Licence

MIT 